{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Example: Transfer Learning using AlexNet and CIFAR-10 Dataset\n",
    "Copyright 2017 The MathWorks, Inc.\n",
    "You will need to download images in order to run this example.\n",
    "Please see the file in this directory: DownloadCIFAR10.m Running this file will help you download CIFAR10 if you choose to use those images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring in Alex Net\n",
    "If this is your first time running this code, this may cause an error message to occur. Follow the link to download AlexNet. You'll only need to download alexnet once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = alexnet;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Layers\n",
    "Visualize the layers of AlexNet, what do we see about this architecture? What do we have to change for this to work for our new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layers = \n",
      "\n",
      "  25x1 Layer array with layers:\n",
      "\n",
      "     1   'data'     Image Input                   227x227x3 images with 'zerocenter' normalization\n",
      "     2   'conv1'    Convolution                   96 11x11x3 convolutions with stride [4  4] and padding [0  0  0  0]\n",
      "     3   'relu1'    ReLU                          ReLU\n",
      "     4   'norm1'    Cross Channel Normalization   cross channel normalization with 5 channels per element\n",
      "     5   'pool1'    Max Pooling                   3x3 max pooling with stride [2  2] and padding [0  0  0  0]\n",
      "     6   'conv2'    Grouped Convolution           2 groups of 128 5x5x48 convolutions with stride [1  1] and padding [2  2  2  2]\n",
      "     7   'relu2'    ReLU                          ReLU\n",
      "     8   'norm2'    Cross Channel Normalization   cross channel normalization with 5 channels per element\n",
      "     9   'pool2'    Max Pooling                   3x3 max pooling with stride [2  2] and padding [0  0  0  0]\n",
      "    10   'conv3'    Convolution                   384 3x3x256 convolutions with stride [1  1] and padding [1  1  1  1]\n",
      "    11   'relu3'    ReLU                          ReLU\n",
      "    12   'conv4'    Grouped Convolution           2 groups of 192 3x3x192 convolutions with stride [1  1] and padding [1  1  1  1]\n",
      "    13   'relu4'    ReLU                          ReLU\n",
      "    14   'conv5'    Grouped Convolution           2 groups of 128 3x3x192 convolutions with stride [1  1] and padding [1  1  1  1]\n",
      "    15   'relu5'    ReLU                          ReLU\n",
      "    16   'pool5'    Max Pooling                   3x3 max pooling with stride [2  2] and padding [0  0  0  0]\n",
      "    17   'fc6'      Fully Connected               4096 fully connected layer\n",
      "    18   'relu6'    ReLU                          ReLU\n",
      "    19   'drop6'    Dropout                       50% dropout\n",
      "    20   'fc7'      Fully Connected               4096 fully connected layer\n",
      "    21   'relu7'    ReLU                          ReLU\n",
      "    22   'drop7'    Dropout                       50% dropout\n",
      "    23   'fc8'      Fully Connected               1000 fully connected layer\n",
      "    24   'prob'     Softmax                       softmax\n",
      "    25   'output'   Classification Output         crossentropyex with 'tench' and 999 other classes\n"
     ]
    }
   ],
   "source": [
    "layers = net.Layers;\n",
    "\n",
    "layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Set up training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "imds = \n",
      "\n",
      "  ImageDatastore with properties:\n",
      "\n",
      "                       Files: {\n",
      "                              ' .../Github/matlab-paths/DeepLearning/cifar10Train/deer/image10024.png';\n",
      "                              ' .../Github/matlab-paths/DeepLearning/cifar10Train/deer/image10068.png';\n",
      "                              ' .../Github/matlab-paths/DeepLearning/cifar10Train/deer/image10106.png'\n",
      "                               ... and 1997 more\n",
      "                              }\n",
      "                      Labels: [deer; deer; deer ... and 1997 more categorical]\n",
      "    AlternateFileSystemRoots: {}\n",
      "                    ReadSize: 1\n",
      "                     ReadFcn: @readDatastoreImage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rootFolder = 'cifar10Train';\n",
    "categories = {'deer','dog','frog','cat'};\n",
    "imds = imageDatastore(fullfile(rootFolder, categories), 'LabelSource', 'foldernames');\n",
    "\n",
    "imds = splitEachLabel(imds, 500, 'randomize') % we only need 500 images per class\n",
    "imds.ReadFcn = @readFunctionTrain;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take layers from Alex Net, then add our own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layers = \n",
      "\n",
      "  27x1 Layer array with layers:\n",
      "\n",
      "     1   'data'        Image Input                   227x227x3 images with 'zerocenter' normalization\n",
      "     2   'conv1'       Convolution                   96 11x11x3 convolutions with stride [4  4] and padding [0  0  0  0]\n",
      "     3   'relu1'       ReLU                          ReLU\n",
      "     4   'norm1'       Cross Channel Normalization   cross channel normalization with 5 channels per element\n",
      "     5   'pool1'       Max Pooling                   3x3 max pooling with stride [2  2] and padding [0  0  0  0]\n",
      "     6   'conv2'       Grouped Convolution           2 groups of 128 5x5x48 convolutions with stride [1  1] and padding [2  2  2  2]\n",
      "     7   'relu2'       ReLU                          ReLU\n",
      "     8   'norm2'       Cross Channel Normalization   cross channel normalization with 5 channels per element\n",
      "     9   'pool2'       Max Pooling                   3x3 max pooling with stride [2  2] and padding [0  0  0  0]\n",
      "    10   'conv3'       Convolution                   384 3x3x256 convolutions with stride [1  1] and padding [1  1  1  1]\n",
      "    11   'relu3'       ReLU                          ReLU\n",
      "    12   'conv4'       Grouped Convolution           2 groups of 192 3x3x192 convolutions with stride [1  1] and padding [1  1  1  1]\n",
      "    13   'relu4'       ReLU                          ReLU\n",
      "    14   'conv5'       Grouped Convolution           2 groups of 128 3x3x192 convolutions with stride [1  1] and padding [1  1  1  1]\n",
      "    15   'relu5'       ReLU                          ReLU\n",
      "    16   'pool5'       Max Pooling                   3x3 max pooling with stride [2  2] and padding [0  0  0  0]\n",
      "    17   'fc6'         Fully Connected               4096 fully connected layer\n",
      "    18   'relu6'       ReLU                          ReLU\n",
      "    19   'drop6'       Dropout                       50% dropout\n",
      "    20   'fc7'         Fully Connected               4096 fully connected layer\n",
      "    21   'relu7'       ReLU                          ReLU\n",
      "    22   'drop7'       Dropout                       50% dropout\n",
      "    23   'special_2'   Fully Connected               64 fully connected layer\n",
      "    24   ''            ReLU                          ReLU\n",
      "    25   'fc8_2 '      Fully Connected               4 fully connected layer\n",
      "    26   ''            Softmax                       softmax\n",
      "    27   ''            Classification Output         crossentropyex\n"
     ]
    }
   ],
   "source": [
    "layers = layers(1:end-3);\n",
    "\n",
    "layers(end+1) = fullyConnectedLayer(64, 'Name', 'special_2');\n",
    "layers(end+1) = reluLayer;\n",
    "layers(end+1) = fullyConnectedLayer(4, 'Name', 'fc8_2 ');\n",
    "layers(end+1) = softmaxLayer;\n",
    "layers(end+1) = classificationLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune learning rates [advanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers(end-2).WeightLearnRateFactor = 10;\n",
    "layers(end-2).WeightL2Factor = 1;\n",
    "layers(end-2).BiasLearnRateFactor = 20;\n",
    "layers(end-2).BiasL2Factor = 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other training options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = trainingOptions('sgdm', ...\n",
    "    'LearnRateSchedule', 'none',...\n",
    "    'InitialLearnRate', .0001,... \n",
    "    'MaxEpochs', 20, ...\n",
    "    'MiniBatchSize', 128);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train! \n",
    "Please note this may take a few minutes or longer depending on hardware. Training with a GPU is strongly encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on single GPU.\n",
      "Initializing input data normalization.\n",
      "|========================================================================================|\n",
      "|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Mini-batch  |  Base Learning  |\n",
      "|         |             |   (hh:mm:ss)   |   Accuracy   |     Loss     |      Rate       |\n",
      "|========================================================================================|\n",
      "|       1 |           1 |       00:00:05 |       36.72% |       2.3009 |      1.0000e-04 |\n",
      "|       4 |          50 |       00:02:51 |       59.38% |       1.0367 |      1.0000e-04 |\n",
      "|       7 |         100 |       00:06:22 |       71.88% |       0.6788 |      1.0000e-04 |\n",
      "|      10 |         150 |       00:07:28 |       78.12% |       0.5960 |      1.0000e-04 |\n",
      "|      14 |         200 |       00:09:40 |       84.38% |       0.4406 |      1.0000e-04 |\n",
      "|      17 |         250 |       00:10:36 |       87.50% |       0.3406 |      1.0000e-04 |\n",
      "|      20 |         300 |       00:13:27 |       86.72% |       0.3366 |      1.0000e-04 |\n",
      "|========================================================================================|\n"
     ]
    }
   ],
   "source": [
    "convnet = trainNetwork(imds, layers, opts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "Set up test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootFolder = 'cifar10Test';\n",
    "testDS = imageDatastore(fullfile(rootFolder, categories), 'LabelSource', 'foldernames');\n",
    "testDS.ReadFcn = @readFunctionTrain;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "[labels,err_test] = classify(convnet, testDS, 'MiniBatchSize', 64);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "    0.8023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confMat = confusionmat(testDS.Labels, labels);\n",
    "confMat = confMat./sum(confMat,2);\n",
    "mean(diag(confMat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab R2019a",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.16.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
